{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a780776",
   "metadata": {},
   "source": [
    "## Dataloader for CUB Birds, FGVC Aircraft, and FoodX dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5bdd09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import VisionDataset\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09095ab",
   "metadata": {},
   "source": [
    "## 1 - Dataloader for CUB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44bbed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUBDataset(torchvision.datasets.ImageFolder):\n",
    "    \"\"\"\n",
    "    Dataset class for CUB Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_root_path, caption_root_path=None, split=\"train\", *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_root_path:      path to dir containing images and lists folders\n",
    "            caption_root_path:    path to dir containing captions\n",
    "            split:          train / test\n",
    "            *args:\n",
    "            **kwargs:\n",
    "        \"\"\"\n",
    "        image_info = self.get_file_content(f\"{image_root_path}/images.txt\")\n",
    "        self.image_id_to_name = {y[0]: y[1] for y in [x.strip().split(\" \") for x in image_info]}\n",
    "        split_info = self.get_file_content(f\"{image_root_path}/train_test_split.txt\")\n",
    "        self.split_info = {self.image_id_to_name[y[0]]: y[1] for y in [x.strip().split(\" \") for x in split_info]}\n",
    "        self.split = \"1\" if split == \"train\" else \"0\"\n",
    "        self.caption_root_path = caption_root_path\n",
    "\n",
    "        super(CUBDataset, self).__init__(root=f\"{image_root_path}/images\", is_valid_file=self.is_valid_file,\n",
    "                                         *args, **kwargs)\n",
    "\n",
    "    def is_valid_file(self, x):\n",
    "        return self.split_info[(x[len(self.root) + 1:])] == self.split\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_content(file_path):\n",
    "        with open(file_path) as fo:\n",
    "            content = fo.readlines()\n",
    "        return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da222c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/apps/local/shared/CV703/datasets/CUB/CUB_200_2011\"\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "# write data transform here as per the requirement\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "train_dataset_cub = CUBDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"train\")\n",
    "test_dataset_cub = CUBDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"test\")\n",
    "\n",
    "\n",
    "# load in into the torch dataloader to get variable batch size, shuffle \n",
    "train_loader_cub = torch.utils.data.DataLoader(train_dataset_cub, batch_size=32, drop_last=True, shuffle=True)\n",
    "test_loader_cub = torch.utils.data.DataLoader(test_dataset_cub, batch_size=32, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30ac24",
   "metadata": {},
   "source": [
    "### Test the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154bf131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5994, 5794)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset_cub), len(test_dataset_cub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5188b9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 182)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader_cub), len(test_loader_cub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4efe971b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "tensor([186, 116,  22, 113, 170, 188,  27,   9, 186, 149, 111,  23,   4,  76,\n",
      "        165,  65, 194,  78, 198, 112,  60, 166,  63,  49, 190,  37,  24, 139,\n",
      "         70, 168,  94, 119])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, labels) in enumerate(train_loader_cub):\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    print('='*50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b6e9ef",
   "metadata": {},
   "source": [
    "## 2 - Dataloader for FGVC Aircraft Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb39850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGVCAircraft(VisionDataset):\n",
    "    \"\"\"\n",
    "    FGVC-Aircraft <http://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/>`_ Dataset.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory of the dataset.\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        class_type (string, optional): choose from ('variant', 'family', 'manufacturer').\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "    \n",
    "    class_types = ('variant', 'family', 'manufacturer')\n",
    "    splits = ('train', 'val', 'trainval', 'test')\n",
    "    img_folder = os.path.join('data', 'images')\n",
    "\n",
    "    def __init__(self, root, train=True, class_type='variant', transform=None,\n",
    "                 target_transform=None):\n",
    "        super(FGVCAircraft, self).__init__(root, transform=transform, target_transform=target_transform)\n",
    "        split = 'trainval' if train else 'test'\n",
    "        if split not in self.splits:\n",
    "            raise ValueError('Split \"{}\" not found. Valid splits are: {}'.format(\n",
    "                split, ', '.join(self.splits),\n",
    "            ))\n",
    "        if class_type not in self.class_types:\n",
    "            raise ValueError('Class type \"{}\" not found. Valid class types are: {}'.format(\n",
    "                class_type, ', '.join(self.class_types),\n",
    "            ))\n",
    "\n",
    "        self.class_type = class_type\n",
    "        self.split = split\n",
    "        self.classes_file = os.path.join(self.root, 'data',\n",
    "                                         'images_%s_%s.txt' % (self.class_type, self.split))\n",
    "\n",
    "        (image_ids, targets, classes, class_to_idx) = self.find_classes()\n",
    "        samples = self.make_dataset(image_ids, targets)\n",
    "\n",
    "        self.loader = default_loader\n",
    "\n",
    "        self.samples = samples\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def find_classes(self):\n",
    "        # read classes file, separating out image IDs and class names\n",
    "        image_ids = []\n",
    "        targets = []\n",
    "        with open(self.classes_file, 'r') as f:\n",
    "            for line in f:\n",
    "                split_line = line.split(' ')\n",
    "                image_ids.append(split_line[0])\n",
    "                targets.append(' '.join(split_line[1:]))\n",
    "\n",
    "        # index class names\n",
    "        classes = np.unique(targets)\n",
    "        class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "        targets = [class_to_idx[c] for c in targets]\n",
    "        \n",
    "        # Modify class index as we are going to concat to CUB dataset\n",
    "        num_cub_classes = len(train_dataset_cub.class_to_idx)\n",
    "        targets = [t + num_cub_classes for t in targets]\n",
    "\n",
    "        return image_ids, targets, classes, class_to_idx\n",
    "\n",
    "    def make_dataset(self, image_ids, targets):\n",
    "        assert (len(image_ids) == len(targets))\n",
    "        images = []\n",
    "        for i in range(len(image_ids)):\n",
    "            item = (os.path.join(self.root, self.img_folder,\n",
    "                                 '%s.jpg' % image_ids[i]), targets[i])\n",
    "            images.append(item)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83aac34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/apps/local/shared/CV703/datasets/fgvc-aircraft-2013b\"\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "# write data transform here as per the requirement\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "train_dataset_aircraft = FGVCAircraft(root=f\"{data_root}\", transform=data_transform, train=True)\n",
    "test_dataset_aircraft = FGVCAircraft(root=f\"{data_root}\", transform=data_transform, train=False)\n",
    "\n",
    "\n",
    "# load in into the torch dataloader to get variable batch size, shuffle \n",
    "train_loader_aircraft = torch.utils.data.DataLoader(train_dataset_aircraft, batch_size=32, drop_last=True, shuffle=True)\n",
    "test_loader_aircraft = torch.utils.data.DataLoader(test_dataset_aircraft, batch_size=32, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd5cc5",
   "metadata": {},
   "source": [
    "### Test the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e96d616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6667, 3333)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset_aircraft), len(test_dataset_aircraft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1dac550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 105)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader_aircraft), len(test_loader_aircraft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cadc7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "tensor([235, 241, 215, 245, 252, 244, 226, 239, 222, 247, 227, 226, 234, 266,\n",
      "        257, 219, 294, 232, 200, 297, 236, 230, 278, 210, 279, 226, 247, 235,\n",
      "        210, 231, 204, 258])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, labels) in enumerate(train_loader_aircraft):\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    print('='*50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc228b9a",
   "metadata": {},
   "source": [
    "## Concatenate CUB Birds and FGVC Aircraft Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92cb9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45774c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_dataset_train = ConcatDataset([train_dataset_cub, train_dataset_aircraft])\n",
    "concat_dataset_test = ConcatDataset([test_dataset_cub, test_dataset_aircraft])\n",
    "\n",
    "concat_loader_train = torch.utils.data.DataLoader(\n",
    "             concat_dataset_train,\n",
    "             batch_size=128, shuffle=True,\n",
    "             num_workers=1, pin_memory=True\n",
    "            )\n",
    "concat_loader_test = torch.utils.data.DataLoader(\n",
    "             concat_dataset_test,\n",
    "             batch_size=128, shuffle=False,\n",
    "             num_workers=1, pin_memory=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d92d42d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12661, 9127)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concat_dataset_train), len(concat_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "448e177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 224, 224])\n",
      "tensor([243, 283,  35, 265, 247, 218, 210, 200, 289, 209, 201, 133, 255, 188,\n",
      "        138, 242, 139,   1, 136, 267, 146, 226,  25, 244, 240, 224, 250, 275,\n",
      "        264, 216, 299, 265, 213, 276,  53, 254, 182, 128, 252,  57,  75,  52,\n",
      "        161,  82, 206, 277, 215, 272, 101, 236,  39, 220, 244, 220, 183, 157,\n",
      "        253, 173, 137, 216, 249, 132, 261, 157, 177,  62, 276, 239, 258, 147,\n",
      "        206, 101, 157, 212, 246, 257, 274, 211, 221, 169,  82, 238, 179,  31,\n",
      "        242, 126, 228, 261, 280, 105,  54, 237,  59,  23, 141,  50,  40, 272,\n",
      "        255, 239, 109, 219, 127, 264,  59, 187, 104, 258, 296, 151, 278, 119,\n",
      "        166,  81, 214,  68, 128,  28, 251, 294, 205, 288, 223, 267, 298,  60,\n",
      "        269, 249])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, labels) in enumerate(concat_loader_train):\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    print('='*50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff56f3",
   "metadata": {},
   "source": [
    "### Way to get information about class names --> Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fddee1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset CUBDataset\n",
       "     Number of datapoints: 5994\n",
       "     Root location: /apps/local/shared/CV703/datasets/CUB/CUB_200_2011/images\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
       "            ),\n",
       " Dataset FGVCAircraft\n",
       "     Number of datapoints: 6667\n",
       "     Root location: /apps/local/shared/CV703/datasets/fgvc-aircraft-2013b\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
       "            )]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_dataset_train.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c29bb352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'001.Black_footed_Albatross': 0,\n",
       " '002.Laysan_Albatross': 1,\n",
       " '003.Sooty_Albatross': 2,\n",
       " '004.Groove_billed_Ani': 3,\n",
       " '005.Crested_Auklet': 4,\n",
       " '006.Least_Auklet': 5,\n",
       " '007.Parakeet_Auklet': 6,\n",
       " '008.Rhinoceros_Auklet': 7,\n",
       " '009.Brewer_Blackbird': 8,\n",
       " '010.Red_winged_Blackbird': 9,\n",
       " '011.Rusty_Blackbird': 10,\n",
       " '012.Yellow_headed_Blackbird': 11,\n",
       " '013.Bobolink': 12,\n",
       " '014.Indigo_Bunting': 13,\n",
       " '015.Lazuli_Bunting': 14,\n",
       " '016.Painted_Bunting': 15,\n",
       " '017.Cardinal': 16,\n",
       " '018.Spotted_Catbird': 17,\n",
       " '019.Gray_Catbird': 18,\n",
       " '020.Yellow_breasted_Chat': 19,\n",
       " '021.Eastern_Towhee': 20,\n",
       " '022.Chuck_will_Widow': 21,\n",
       " '023.Brandt_Cormorant': 22,\n",
       " '024.Red_faced_Cormorant': 23,\n",
       " '025.Pelagic_Cormorant': 24,\n",
       " '026.Bronzed_Cowbird': 25,\n",
       " '027.Shiny_Cowbird': 26,\n",
       " '028.Brown_Creeper': 27,\n",
       " '029.American_Crow': 28,\n",
       " '030.Fish_Crow': 29,\n",
       " '031.Black_billed_Cuckoo': 30,\n",
       " '032.Mangrove_Cuckoo': 31,\n",
       " '033.Yellow_billed_Cuckoo': 32,\n",
       " '034.Gray_crowned_Rosy_Finch': 33,\n",
       " '035.Purple_Finch': 34,\n",
       " '036.Northern_Flicker': 35,\n",
       " '037.Acadian_Flycatcher': 36,\n",
       " '038.Great_Crested_Flycatcher': 37,\n",
       " '039.Least_Flycatcher': 38,\n",
       " '040.Olive_sided_Flycatcher': 39,\n",
       " '041.Scissor_tailed_Flycatcher': 40,\n",
       " '042.Vermilion_Flycatcher': 41,\n",
       " '043.Yellow_bellied_Flycatcher': 42,\n",
       " '044.Frigatebird': 43,\n",
       " '045.Northern_Fulmar': 44,\n",
       " '046.Gadwall': 45,\n",
       " '047.American_Goldfinch': 46,\n",
       " '048.European_Goldfinch': 47,\n",
       " '049.Boat_tailed_Grackle': 48,\n",
       " '050.Eared_Grebe': 49,\n",
       " '051.Horned_Grebe': 50,\n",
       " '052.Pied_billed_Grebe': 51,\n",
       " '053.Western_Grebe': 52,\n",
       " '054.Blue_Grosbeak': 53,\n",
       " '055.Evening_Grosbeak': 54,\n",
       " '056.Pine_Grosbeak': 55,\n",
       " '057.Rose_breasted_Grosbeak': 56,\n",
       " '058.Pigeon_Guillemot': 57,\n",
       " '059.California_Gull': 58,\n",
       " '060.Glaucous_winged_Gull': 59,\n",
       " '061.Heermann_Gull': 60,\n",
       " '062.Herring_Gull': 61,\n",
       " '063.Ivory_Gull': 62,\n",
       " '064.Ring_billed_Gull': 63,\n",
       " '065.Slaty_backed_Gull': 64,\n",
       " '066.Western_Gull': 65,\n",
       " '067.Anna_Hummingbird': 66,\n",
       " '068.Ruby_throated_Hummingbird': 67,\n",
       " '069.Rufous_Hummingbird': 68,\n",
       " '070.Green_Violetear': 69,\n",
       " '071.Long_tailed_Jaeger': 70,\n",
       " '072.Pomarine_Jaeger': 71,\n",
       " '073.Blue_Jay': 72,\n",
       " '074.Florida_Jay': 73,\n",
       " '075.Green_Jay': 74,\n",
       " '076.Dark_eyed_Junco': 75,\n",
       " '077.Tropical_Kingbird': 76,\n",
       " '078.Gray_Kingbird': 77,\n",
       " '079.Belted_Kingfisher': 78,\n",
       " '080.Green_Kingfisher': 79,\n",
       " '081.Pied_Kingfisher': 80,\n",
       " '082.Ringed_Kingfisher': 81,\n",
       " '083.White_breasted_Kingfisher': 82,\n",
       " '084.Red_legged_Kittiwake': 83,\n",
       " '085.Horned_Lark': 84,\n",
       " '086.Pacific_Loon': 85,\n",
       " '087.Mallard': 86,\n",
       " '088.Western_Meadowlark': 87,\n",
       " '089.Hooded_Merganser': 88,\n",
       " '090.Red_breasted_Merganser': 89,\n",
       " '091.Mockingbird': 90,\n",
       " '092.Nighthawk': 91,\n",
       " '093.Clark_Nutcracker': 92,\n",
       " '094.White_breasted_Nuthatch': 93,\n",
       " '095.Baltimore_Oriole': 94,\n",
       " '096.Hooded_Oriole': 95,\n",
       " '097.Orchard_Oriole': 96,\n",
       " '098.Scott_Oriole': 97,\n",
       " '099.Ovenbird': 98,\n",
       " '100.Brown_Pelican': 99,\n",
       " '101.White_Pelican': 100,\n",
       " '102.Western_Wood_Pewee': 101,\n",
       " '103.Sayornis': 102,\n",
       " '104.American_Pipit': 103,\n",
       " '105.Whip_poor_Will': 104,\n",
       " '106.Horned_Puffin': 105,\n",
       " '107.Common_Raven': 106,\n",
       " '108.White_necked_Raven': 107,\n",
       " '109.American_Redstart': 108,\n",
       " '110.Geococcyx': 109,\n",
       " '111.Loggerhead_Shrike': 110,\n",
       " '112.Great_Grey_Shrike': 111,\n",
       " '113.Baird_Sparrow': 112,\n",
       " '114.Black_throated_Sparrow': 113,\n",
       " '115.Brewer_Sparrow': 114,\n",
       " '116.Chipping_Sparrow': 115,\n",
       " '117.Clay_colored_Sparrow': 116,\n",
       " '118.House_Sparrow': 117,\n",
       " '119.Field_Sparrow': 118,\n",
       " '120.Fox_Sparrow': 119,\n",
       " '121.Grasshopper_Sparrow': 120,\n",
       " '122.Harris_Sparrow': 121,\n",
       " '123.Henslow_Sparrow': 122,\n",
       " '124.Le_Conte_Sparrow': 123,\n",
       " '125.Lincoln_Sparrow': 124,\n",
       " '126.Nelson_Sharp_tailed_Sparrow': 125,\n",
       " '127.Savannah_Sparrow': 126,\n",
       " '128.Seaside_Sparrow': 127,\n",
       " '129.Song_Sparrow': 128,\n",
       " '130.Tree_Sparrow': 129,\n",
       " '131.Vesper_Sparrow': 130,\n",
       " '132.White_crowned_Sparrow': 131,\n",
       " '133.White_throated_Sparrow': 132,\n",
       " '134.Cape_Glossy_Starling': 133,\n",
       " '135.Bank_Swallow': 134,\n",
       " '136.Barn_Swallow': 135,\n",
       " '137.Cliff_Swallow': 136,\n",
       " '138.Tree_Swallow': 137,\n",
       " '139.Scarlet_Tanager': 138,\n",
       " '140.Summer_Tanager': 139,\n",
       " '141.Artic_Tern': 140,\n",
       " '142.Black_Tern': 141,\n",
       " '143.Caspian_Tern': 142,\n",
       " '144.Common_Tern': 143,\n",
       " '145.Elegant_Tern': 144,\n",
       " '146.Forsters_Tern': 145,\n",
       " '147.Least_Tern': 146,\n",
       " '148.Green_tailed_Towhee': 147,\n",
       " '149.Brown_Thrasher': 148,\n",
       " '150.Sage_Thrasher': 149,\n",
       " '151.Black_capped_Vireo': 150,\n",
       " '152.Blue_headed_Vireo': 151,\n",
       " '153.Philadelphia_Vireo': 152,\n",
       " '154.Red_eyed_Vireo': 153,\n",
       " '155.Warbling_Vireo': 154,\n",
       " '156.White_eyed_Vireo': 155,\n",
       " '157.Yellow_throated_Vireo': 156,\n",
       " '158.Bay_breasted_Warbler': 157,\n",
       " '159.Black_and_white_Warbler': 158,\n",
       " '160.Black_throated_Blue_Warbler': 159,\n",
       " '161.Blue_winged_Warbler': 160,\n",
       " '162.Canada_Warbler': 161,\n",
       " '163.Cape_May_Warbler': 162,\n",
       " '164.Cerulean_Warbler': 163,\n",
       " '165.Chestnut_sided_Warbler': 164,\n",
       " '166.Golden_winged_Warbler': 165,\n",
       " '167.Hooded_Warbler': 166,\n",
       " '168.Kentucky_Warbler': 167,\n",
       " '169.Magnolia_Warbler': 168,\n",
       " '170.Mourning_Warbler': 169,\n",
       " '171.Myrtle_Warbler': 170,\n",
       " '172.Nashville_Warbler': 171,\n",
       " '173.Orange_crowned_Warbler': 172,\n",
       " '174.Palm_Warbler': 173,\n",
       " '175.Pine_Warbler': 174,\n",
       " '176.Prairie_Warbler': 175,\n",
       " '177.Prothonotary_Warbler': 176,\n",
       " '178.Swainson_Warbler': 177,\n",
       " '179.Tennessee_Warbler': 178,\n",
       " '180.Wilson_Warbler': 179,\n",
       " '181.Worm_eating_Warbler': 180,\n",
       " '182.Yellow_Warbler': 181,\n",
       " '183.Northern_Waterthrush': 182,\n",
       " '184.Louisiana_Waterthrush': 183,\n",
       " '185.Bohemian_Waxwing': 184,\n",
       " '186.Cedar_Waxwing': 185,\n",
       " '187.American_Three_toed_Woodpecker': 186,\n",
       " '188.Pileated_Woodpecker': 187,\n",
       " '189.Red_bellied_Woodpecker': 188,\n",
       " '190.Red_cockaded_Woodpecker': 189,\n",
       " '191.Red_headed_Woodpecker': 190,\n",
       " '192.Downy_Woodpecker': 191,\n",
       " '193.Bewick_Wren': 192,\n",
       " '194.Cactus_Wren': 193,\n",
       " '195.Carolina_Wren': 194,\n",
       " '196.House_Wren': 195,\n",
       " '197.Marsh_Wren': 196,\n",
       " '198.Rock_Wren': 197,\n",
       " '199.Winter_Wren': 198,\n",
       " '200.Common_Yellowthroat': 199}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_dataset_train.datasets[0].class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1ae3fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'707-320\\n': 0,\n",
       " '727-200\\n': 1,\n",
       " '737-200\\n': 2,\n",
       " '737-300\\n': 3,\n",
       " '737-400\\n': 4,\n",
       " '737-500\\n': 5,\n",
       " '737-600\\n': 6,\n",
       " '737-700\\n': 7,\n",
       " '737-800\\n': 8,\n",
       " '737-900\\n': 9,\n",
       " '747-100\\n': 10,\n",
       " '747-200\\n': 11,\n",
       " '747-300\\n': 12,\n",
       " '747-400\\n': 13,\n",
       " '757-200\\n': 14,\n",
       " '757-300\\n': 15,\n",
       " '767-200\\n': 16,\n",
       " '767-300\\n': 17,\n",
       " '767-400\\n': 18,\n",
       " '777-200\\n': 19,\n",
       " '777-300\\n': 20,\n",
       " 'A300B4\\n': 21,\n",
       " 'A310\\n': 22,\n",
       " 'A318\\n': 23,\n",
       " 'A319\\n': 24,\n",
       " 'A320\\n': 25,\n",
       " 'A321\\n': 26,\n",
       " 'A330-200\\n': 27,\n",
       " 'A330-300\\n': 28,\n",
       " 'A340-200\\n': 29,\n",
       " 'A340-300\\n': 30,\n",
       " 'A340-500\\n': 31,\n",
       " 'A340-600\\n': 32,\n",
       " 'A380\\n': 33,\n",
       " 'ATR-42\\n': 34,\n",
       " 'ATR-72\\n': 35,\n",
       " 'An-12\\n': 36,\n",
       " 'BAE 146-200\\n': 37,\n",
       " 'BAE 146-300\\n': 38,\n",
       " 'BAE-125\\n': 39,\n",
       " 'Beechcraft 1900\\n': 40,\n",
       " 'Boeing 717\\n': 41,\n",
       " 'C-130\\n': 42,\n",
       " 'C-47\\n': 43,\n",
       " 'CRJ-200\\n': 44,\n",
       " 'CRJ-700\\n': 45,\n",
       " 'CRJ-900\\n': 46,\n",
       " 'Cessna 172\\n': 47,\n",
       " 'Cessna 208\\n': 48,\n",
       " 'Cessna 525\\n': 49,\n",
       " 'Cessna 560\\n': 50,\n",
       " 'Challenger 600\\n': 51,\n",
       " 'DC-10\\n': 52,\n",
       " 'DC-3\\n': 53,\n",
       " 'DC-6\\n': 54,\n",
       " 'DC-8\\n': 55,\n",
       " 'DC-9-30\\n': 56,\n",
       " 'DH-82\\n': 57,\n",
       " 'DHC-1\\n': 58,\n",
       " 'DHC-6\\n': 59,\n",
       " 'DHC-8-100\\n': 60,\n",
       " 'DHC-8-300\\n': 61,\n",
       " 'DR-400\\n': 62,\n",
       " 'Dornier 328\\n': 63,\n",
       " 'E-170\\n': 64,\n",
       " 'E-190\\n': 65,\n",
       " 'E-195\\n': 66,\n",
       " 'EMB-120\\n': 67,\n",
       " 'ERJ 135\\n': 68,\n",
       " 'ERJ 145\\n': 69,\n",
       " 'Embraer Legacy 600\\n': 70,\n",
       " 'Eurofighter Typhoon\\n': 71,\n",
       " 'F-16A/B\\n': 72,\n",
       " 'F/A-18\\n': 73,\n",
       " 'Falcon 2000\\n': 74,\n",
       " 'Falcon 900\\n': 75,\n",
       " 'Fokker 100\\n': 76,\n",
       " 'Fokker 50\\n': 77,\n",
       " 'Fokker 70\\n': 78,\n",
       " 'Global Express\\n': 79,\n",
       " 'Gulfstream IV\\n': 80,\n",
       " 'Gulfstream V\\n': 81,\n",
       " 'Hawk T1\\n': 82,\n",
       " 'Il-76\\n': 83,\n",
       " 'L-1011\\n': 84,\n",
       " 'MD-11\\n': 85,\n",
       " 'MD-80\\n': 86,\n",
       " 'MD-87\\n': 87,\n",
       " 'MD-90\\n': 88,\n",
       " 'Metroliner\\n': 89,\n",
       " 'Model B200\\n': 90,\n",
       " 'PA-28\\n': 91,\n",
       " 'SR-20\\n': 92,\n",
       " 'Saab 2000\\n': 93,\n",
       " 'Saab 340\\n': 94,\n",
       " 'Spitfire\\n': 95,\n",
       " 'Tornado\\n': 96,\n",
       " 'Tu-134\\n': 97,\n",
       " 'Tu-154\\n': 98,\n",
       " 'Yak-42\\n': 99}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_dataset_train.datasets[1].class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb2810",
   "metadata": {},
   "source": [
    "## 3. Dataloader for Food Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb249015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "827ee8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/apps/local/shared/CV703/datasets/FoodX/food_dataset\"\n",
    "\n",
    "split = 'train'\n",
    "train_df = pd.read_csv(f'{data_dir}/annot/{split}_info.csv', names= ['image_name','label'])\n",
    "train_df['path'] = train_df['image_name'].map(lambda x: os.path.join(f'{data_dir}/{split}_set/', x))\n",
    "\n",
    "\n",
    "split = 'val'\n",
    "val_df = pd.read_csv(f'{data_dir}/annot/{split}_info.csv', names= ['image_name','label'])\n",
    "val_df['path'] = val_df['image_name'].map(lambda x: os.path.join(f'{data_dir}/{split}_set/', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b95636e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224, 224))\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a32560d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FOODDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        return (\n",
    "            data_transform(Image.open(row[\"path\"])), row['label']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd36013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FOODDataset(train_df)\n",
    "val_dataset = FOODDataset(val_df)\n",
    "\n",
    "# load in into the torch dataloader to get variable batch size, shuffle \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, drop_last=True, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d0c258c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118475, 11994)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fda971b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3702, 375)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7455c083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "tensor([173,   8, 154, 217,  44,  33,  68, 146,   3,  53,  37, 130, 175, 230,\n",
      "         23, 233,  82, 146,  26, 138,  48, 147, 136, 154, 178, 157, 217, 181,\n",
      "         33, 219, 108, 104])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, labels) in enumerate(val_loader):\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    print('='*50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217be99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import trainer\n",
    "from utils import plot_results, LinearLR, WarmupLR\n",
    "from models.model import get_model\n",
    "from torch.utils.data import ConcatDataset \n",
    "from dataset import CUBDataset, FGVCAircraft, FOODDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "import torchvision\n",
    "from torch.utils.data import default_collate\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "from engine import val_step\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "config = yaml.load(open('finetune_config.yaml', 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "LEARNING_RATE = [float(i) for i in config[\"LEARNING_RATE\"]]\n",
    "LEARNING_SCHEDULER = config[\"LEARNING_SCHEDULER\"]\n",
    "BATCH_SIZE = int(config[\"BATCH_SIZE\"])\n",
    "NUM_EPOCHS = int(config[\"NUM_EPOCHS\"])\n",
    "\n",
    "LOSS = config[\"LOSS\"]\n",
    "LABEL_SMOOTHING = float(config[\"LABEL_SMOOTHING\"])\n",
    "\n",
    "IMAGE_SIZE = int(config[\"IMAGE_SIZE\"])\n",
    "MODEL = config[\"MODEL\"]\n",
    "INIT_PATH = config[\"INIT_PATH\"]\n",
    "PRETRAINED = config[\"PRETRAINED\"]\n",
    "FREEZE = config[\"FREEZE\"]\n",
    "\n",
    "DATASET = config[\"DATASET\"]\n",
    "CUT_UP_MIX = config[\"CUT_UP_MIX\"]\n",
    "HPC = config[\"HPC\"]\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {DEVICE} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dicts = []\n",
    "val_results = []\n",
    "WEIGHT_PATH = \"/home/nuren.zhaksylyk/Documents/CV703/CV703_Assignment_1/runs/finetune/2024-01-27_20-46-18/CUB/ConvTransNeXtTiny\"\n",
    "\n",
    "def START_seed():\n",
    "    seed = 9\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_seed()\n",
    "\n",
    "dataset_name = [\"CUB\", \"CUB and FGVC-Aircraft\", \"FoodX\"][DATASET]\n",
    "num_classes = [200, 200 + 100, 251][DATASET]\n",
    "\n",
    "#run id is date and time of the run\n",
    "\n",
    "save_root_dir = \"./runs/finetune/\" + dataset_name + '/' + MODEL\n",
    "os.makedirs(save_root_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "#load data\n",
    "transforms_train = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.RandomResizedCrop((IMAGE_SIZE, IMAGE_SIZE), scale=(0.7, 1.0), antialias=True),\n",
    "\n",
    "    # v2.AutoAugment(policy=v2.AutoAugmentPolicy.IMAGENET, ),\n",
    "    v2.RandAugment(num_ops=2, magnitude=10),\n",
    "    v2.RandomErasing(p=0.1),\n",
    "\n",
    "    v2.ToDtype(torch.float, scale=True),\n",
    "    v2.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "transforms_test = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Resize((224, 224), antialias=True),\n",
    "    v2.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "cutmix = v2.CutMix(num_classes=num_classes, alpha=1.0)\n",
    "mixup = v2.MixUp(num_classes=num_classes, alpha=0.2)\n",
    "cutmix_or_mixup = v2.RandomChoice([cutmix, mixup])\n",
    "\n",
    "if CUT_UP_MIX:\n",
    "    def collate_fn(batch):\n",
    "        return cutmix_or_mixup(*default_collate(batch))\n",
    "else:\n",
    "    collate_fn = None\n",
    "\n",
    "if HPC:\n",
    "    dataset_path_prefix = \"/apps/local/shared/CV703/datasets/\"\n",
    "else:\n",
    "    dataset_path_prefix = \"datasets/\"\n",
    "\n",
    "if dataset_name == 'CUB':\n",
    "    dataset_path = dataset_path_prefix + \"CUB/CUB_200_2011\"\n",
    "\n",
    "    train_simple_dataset = CUBDataset(image_root_path=dataset_path, transform=transforms_test, split=\"train\")\n",
    "    train_dataset = CUBDataset(image_root_path=dataset_path, transform=transforms_train, split=\"train\")\n",
    "    test_dataset = CUBDataset(image_root_path=dataset_path, transform=transforms_test, split=\"test\")\n",
    "\n",
    "    train_simple_loader = DataLoader(train_simple_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "    class_names = train_dataset.classes\n",
    "\n",
    "elif dataset_name == 'CUB and FGVC-Aircraft':\n",
    "\n",
    "    dataset_path_cub = dataset_path_prefix + \"CUB/CUB_200_2011\"\n",
    "    train_simple_dataset_cub = CUBDataset(image_root_path=dataset_path_cub, transform=transforms_test, split=\"train\")\n",
    "    train_dataset_cub = CUBDataset(image_root_path=dataset_path_cub, transform=transforms_train, split=\"train\")\n",
    "    test_dataset_cub = CUBDataset(image_root_path=dataset_path_cub, transform=transforms_test, split=\"test\")\n",
    "\n",
    "    dataset_path_aircraft = dataset_path_prefix + \"fgvc-aircraft-2013b\"\n",
    "    train_simple_dataset_aircraft = FGVCAircraft(root=dataset_path_aircraft, transform=transforms_test, train=True)\n",
    "    train_dataset_aircraft = FGVCAircraft(root=dataset_path_aircraft, transform=transforms_train, train=True)\n",
    "    test_dataset_aircraft = FGVCAircraft(root=dataset_path_aircraft, transform=transforms_test, train=False)\n",
    "\n",
    "    concat_dataset_train_simple = ConcatDataset([train_simple_dataset_cub, train_simple_dataset_aircraft])\n",
    "    concat_dataset_train = ConcatDataset([train_dataset_cub, train_dataset_aircraft])\n",
    "    concat_dataset_test = ConcatDataset([test_dataset_cub, test_dataset_aircraft])\n",
    "\n",
    "    train_simple_loader = torch.utils.data.DataLoader(\n",
    "                concat_dataset_train_simple,\n",
    "                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                num_workers=8, pin_memory=True,\n",
    "                collate_fn=None\n",
    "                )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "                concat_dataset_train,\n",
    "                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                num_workers=8, pin_memory=True,\n",
    "                collate_fn=collate_fn\n",
    "                )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "                concat_dataset_test,\n",
    "                batch_size=BATCH_SIZE, shuffle=False,\n",
    "                num_workers=8, pin_memory=True\n",
    "                )\n",
    "    \n",
    "    classes_1 = concat_dataset_train.datasets[0].classes\n",
    "    classes_2 = concat_dataset_train.datasets[1].classes\n",
    "\n",
    "    class_names = [*classes_1, *classes_2]\n",
    "\n",
    "elif dataset_name == 'FoodX':\n",
    "    dataset_path = dataset_path_prefix + \"FoodX/food_dataset\"\n",
    "\n",
    "    train_dataset = FOODDataset(data_dir=dataset_path, transform=transforms_train, split=\"train\")\n",
    "    test_dataset = FOODDataset(data_dir=dataset_path, transform=transforms_test, split=\"val\")\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dicts = []\n",
    "val_results = []\n",
    "test_results = []\n",
    "\n",
    "#if there is no test directory create it\n",
    "if not os.path.exists(\"test\"):\n",
    "    os.makedirs(\"test\")\n",
    "\n",
    "#if there is no folder named after dataset inside test directory create it\n",
    "if not os.path.exists(os.path.join(\"test\", dataset_name, MODEL)):\n",
    "    os.makedirs(os.path.join(\"test\", dataset_name, MODEL))\n",
    "\n",
    "test_save_path = os.path.join(\"test\", dataset_name, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def souping(model, state_dicts, alphal):\n",
    "    sd = {k : state_dicts[0][k].clone() * alphal[0] for k in state_dicts[0].keys()}\n",
    "    for i in range(1, len(state_dicts)):\n",
    "        for k in state_dicts[i].keys():\n",
    "            sd[k] = sd[k] + state_dicts[i][k].clone() * alphal[i]\n",
    "    model.load_state_dict(sd)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_souping(state_dicts, val_results, val_loader, loss, DEVICE, num_classes):\n",
    "    ranked_candidates = [i for i in range(len(state_dicts))]\n",
    "    ranked_candidates.sort(key=lambda x: -val_results[x])\n",
    "    print(ranked_candidates)\n",
    "    current_best = val_results[ranked_candidates[0]]\n",
    "    print('currentttttttt bestttttttt', current_best)\n",
    "    best_ingredients = ranked_candidates[:1]\n",
    "\n",
    "    for i in range(1, len(state_dicts)):\n",
    "        # add current index to the ingredients\n",
    "        ingredient_indices = best_ingredients + [ranked_candidates[i]]\n",
    "        alphal = [0 for i in range(len(state_dicts))]\n",
    "        for j in ingredient_indices:\n",
    "            alphal[j] = 1 / len(ingredient_indices)\n",
    "\n",
    "        # benchmark and conditionally append\n",
    "        model = get_model(MODEL, PRETRAINED, num_classes, FREEZE)\n",
    "\n",
    "        greedy_model = souping(model, state_dicts, alphal)\n",
    "        greedy_model.to(DEVICE)\n",
    "        greedy_val_loss, greedy_val_acc = val_step(greedy_model, val_loader, loss, DEVICE)\n",
    "        print(f'Models {ingredient_indices} got {greedy_val_acc} on validation.')\n",
    "        if greedy_val_acc > current_best:\n",
    "            current_best = greedy_val_acc\n",
    "            best_ingredients = ingredient_indices\n",
    "       \n",
    "\n",
    "    alphal = [0 for i in range(len(state_dicts))]\n",
    "    for j in best_ingredients:\n",
    "        alphal[j] = 1 / len(best_ingredients)\n",
    "    greedy_model = souping(model, state_dicts, alphal)\n",
    "    return greedy_model, best_ingredients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_souping_2(state_dicts, val_results, val_loader, loss, DEVICE, num_classes):\n",
    "    ranked_candidates = [i for i in range(len(state_dicts))]\n",
    "    ranked_candidates.sort(key=lambda x: -val_results[x])\n",
    "    print(ranked_candidates)\n",
    "    current_best = val_results[ranked_candidates[0]]\n",
    "    print('currentttttttt bestttttttt', current_best)\n",
    "    best_ingredients = ranked_candidates[:1]\n",
    "    should_restart = True\n",
    "    while should_restart:\n",
    "        should_restart = False\n",
    "        for i in range(1, len(state_dicts)):\n",
    "            if ranked_candidates[i] in best_ingredients:\n",
    "                continue\n",
    "            # add current index to the ingredients\n",
    "            ingredient_indices = best_ingredients + [ranked_candidates[i]]\n",
    "            alphal = [0 for i in range(len(state_dicts))]\n",
    "            for j in ingredient_indices:\n",
    "                alphal[j] = 1 / len(ingredient_indices)\n",
    "\n",
    "            # benchmark and conditionally append\n",
    "            model = get_model(MODEL, PRETRAINED, num_classes, FREEZE)\n",
    "\n",
    "            greedy_model = souping(model, state_dicts, alphal)\n",
    "            greedy_model.to(DEVICE)\n",
    "            greedy_val_loss, greedy_val_acc = val_step(greedy_model, val_loader, loss, DEVICE)\n",
    "            print(f'Models {ingredient_indices} got {greedy_val_acc} on validation.')\n",
    "            if greedy_val_acc > current_best:\n",
    "                should_restart = True\n",
    "                current_best = greedy_val_acc\n",
    "                best_ingredients = ingredient_indices\n",
    "       \n",
    "\n",
    "    alphal = [0 for i in range(len(state_dicts))]\n",
    "    for j in best_ingredients:\n",
    "        alphal[j] = 1 / len(best_ingredients)\n",
    "    greedy_model = souping(model, state_dicts, alphal)\n",
    "    return greedy_model, best_ingredients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "                                        \n",
    "def prune_souping_random(state_dicts, val_results, val_loader, loss, DEVICE, num_classes):\n",
    "    ranked_candidates = [i for i in range(len(state_dicts))]\n",
    "    ranked_candidates.sort(key=lambda x: -val_results[x])\n",
    "    print(ranked_candidates)\n",
    "    current_best = val_results[ranked_candidates[0]]\n",
    "    print('currentttttttt bestttttttt', current_best)\n",
    "    best_ingredients = ranked_candidates\n",
    "    i_s = []\n",
    "    while True:\n",
    "        if len(best_ingredients) == 0:\n",
    "            break\n",
    "        \n",
    "        b = [x for x in range(len(best_ingredients)) if x not in i_s]\n",
    "        \n",
    "        if len(b) == 0:\n",
    "            break\n",
    "\n",
    "        i = random.choice(b)\n",
    "        i_s.append(i)\n",
    "        \n",
    "        ingredient_indices = best_ingredients[:i] + best_ingredients[i+1:]\n",
    "        alphal = [0 for i in range(len(state_dicts))]\n",
    "        for j in ingredient_indices:\n",
    "            alphal[j] = 1 / len(ingredient_indices)\n",
    "        model = get_model(MODEL, PRETRAINED, num_classes, FREEZE)\n",
    "\n",
    "        greedy_model = souping(model, state_dicts, alphal)\n",
    "        greedy_model.to(DEVICE)\n",
    "        greedy_val_loss, greedy_val_acc = val_step(greedy_model, val_loader, loss, DEVICE)\n",
    "        print(f'Models {ingredient_indices} got {greedy_val_acc} on validation.')\n",
    "        if greedy_val_acc > current_best:\n",
    "            current_best = greedy_val_acc\n",
    "            best_ingredients = ingredient_indices\n",
    "            i_s = []\n",
    "            # benchmark and conditionally append\n",
    "            \n",
    "       \n",
    "\n",
    "    alphal = [0 for i in range(len(state_dicts))]\n",
    "    for j in best_ingredients:\n",
    "        alphal[j] = 1 / len(best_ingredients)\n",
    "    greedy_model = souping(model, state_dicts, alphal)\n",
    "    return greedy_model, best_ingredients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                 \n",
    "def prune_souping_sorted(state_dicts, val_results, val_loader, loss, DEVICE, num_classes):\n",
    "    ranked_candidates = [i for i in range(len(state_dicts))]\n",
    "    ranked_candidates.sort(key=lambda x: -val_results[x])\n",
    "    print(ranked_candidates)\n",
    "    current_best = val_results[ranked_candidates[0]]\n",
    "    print('currentttttttt bestttttttt', current_best)\n",
    "    best_ingredients = ranked_candidates\n",
    "    i = 0\n",
    "    while True:\n",
    "        if len(best_ingredients) == 0:\n",
    "            break\n",
    "\n",
    "        if i >= len(best_ingredients):\n",
    "            break\n",
    "        \n",
    "        ingredient_indices = best_ingredients[:i] + best_ingredients[i+1:]\n",
    "        alphal = [0 for i in range(len(state_dicts))]\n",
    "        for j in ingredient_indices:\n",
    "            alphal[j] = 1 / len(ingredient_indices)\n",
    "        model = get_model(MODEL, PRETRAINED, num_classes, FREEZE)\n",
    "\n",
    "        greedy_model = souping(model, state_dicts, alphal)\n",
    "        greedy_model.to(DEVICE)\n",
    "        greedy_val_loss, greedy_val_acc = val_step(greedy_model, val_loader, loss, DEVICE)\n",
    "        print(f'Models {ingredient_indices} got {greedy_val_acc} on validation.')\n",
    "        if greedy_val_acc > current_best:\n",
    "            current_best = greedy_val_acc\n",
    "            best_ingredients = ingredient_indices\n",
    "            i = 0\n",
    "            # benchmark and conditionally append\n",
    "        i+=1\n",
    "       \n",
    "\n",
    "    alphal = [0 for i in range(len(state_dicts))]\n",
    "    for j in best_ingredients:\n",
    "        alphal[j] = 1 / len(best_ingredients)\n",
    "    greedy_model = souping(model, state_dicts, alphal)\n",
    "    return greedy_model, best_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:16<00:00, 11.08it/s]\n",
      "100%|##########| 182/182 [00:19<00:00,  9.12it/s]\n",
      "100%|##########| 182/182 [00:17<00:00, 10.58it/s]\n",
      "100%|##########| 182/182 [00:19<00:00,  9.28it/s]\n",
      "100%|##########| 182/182 [00:16<00:00, 11.33it/s]\n",
      "100%|##########| 182/182 [00:19<00:00,  9.10it/s]\n",
      "100%|##########| 182/182 [00:18<00:00,  9.70it/s]\n",
      "100%|##########| 182/182 [00:18<00:00, 10.00it/s]\n",
      "100%|##########| 182/182 [00:20<00:00,  8.80it/s]\n",
      "100%|##########| 182/182 [00:19<00:00,  9.58it/s]\n",
      "100%|##########| 182/182 [00:19<00:00,  9.33it/s]\n",
      "100%|##########| 182/182 [00:16<00:00, 10.91it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, folder in enumerate(sorted(os.listdir(WEIGHT_PATH))):\n",
    "\n",
    "    model_path = os.path.join(WEIGHT_PATH, folder)\n",
    "    #read config in train_summary.json\n",
    "    train_summary = json.load(open(os.path.join(model_path, \"train_summary.json\"), 'r'))\n",
    "    model_config = train_summary[\"config\"]\n",
    "    \n",
    "    #load model\n",
    "    checkpoint = torch.load(os.path.join(model_path, \"best_model.pth\"), map_location=DEVICE)\n",
    "    state_dicts.append(checkpoint)\n",
    "    model = get_model(MODEL, PRETRAINED, num_classes, FREEZE)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to(DEVICE)\n",
    "    #load loss function\n",
    "    LOSS = model_config[\"LOSS\"]\n",
    "    if LOSS == \"MSE\":\n",
    "        loss = torch.nn.MSELoss()\n",
    "    elif LOSS == \"L1Loss\":\n",
    "        loss = torch.nn.L1Loss()\n",
    "    elif LOSS == \"SmoothL1Loss\":\n",
    "        loss = torch.nn.SmoothL1Loss()\n",
    "    elif LOSS == \"CrossEntropyLoss\":\n",
    "        loss = torch.nn.CrossEntropyLoss()\n",
    "    elif LOSS == \"BCEWithLogitsLoss\":\n",
    "        loss = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    val_loss, val_acc = val_step(model, test_loader, loss, device = DEVICE)\n",
    "\n",
    "    val_results.append({'Model Name': idx,\n",
    "                                    'Val Accuracy': val_acc,\n",
    "                                    'LR': train_summary[\"results\"][\"learning_rate\"][0],\n",
    "                                    })\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model Val Accuracy: 0.8626164998274076\n",
      "Second best model Val Accuracy: 0.8603727994477045\n",
      "Worst model Val Accuracy: 0.8117017604418364\n",
      "Uniform souping ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nuren.zhaksylyk/.conda/envs/CV701_env/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "100%|##########| 182/182 [00:18<00:00,  9.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform souping accuracy: 0.8629616845012081\n",
      "Greedy souping ...\n",
      "[4, 6, 0, 5, 10, 11, 9, 8, 7, 1, 2, 3]\n",
      "currentttttttt bestttttttt 0.8626164998274076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:22<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6] got 0.8631342768381084 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:18<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 0] got 0.8627890921643079 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 5] got 0.8627890921643079 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:15<00:00, 11.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10] got 0.8643424231964101 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:18<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 11] got 0.8634794615119089 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:16<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 9] got 0.8638246461857093 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 8] got 0.8639972385226096 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:17<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 7] got 0.8633068691750087 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:21<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1] got 0.8658957542285123 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:17<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 2] got 0.8629616845012081 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 3] got 0.8626164998274076 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:15<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 0] got 0.8655505695547118 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:19<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 5] got 0.8658957542285123 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:17<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11] got 0.8662409389023127 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:19<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 9] got 0.8658957542285123 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:15<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 8] got 0.8662409389023127 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 7] got 0.8660683465654125 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:16<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 2] got 0.8639972385226096 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:19<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 3] got 0.8641698308595098 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:16<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 0] got 0.8669313082499137 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 0, 5] got 0.8660683465654125 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:17<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 0, 9] got 0.865723161891612 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 0, 8] got 0.8660683465654125 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:16<00:00, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 0, 7] got 0.8665861235761132 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 0, 2] got 0.8653779772178115 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:17<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 0, 3] got 0.8636520538488092 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:19<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 0, 5] got 0.8660683465654125 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:15<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 0, 9] got 0.865723161891612 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:19<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 0, 8] got 0.8660683465654125 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:16<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 0, 7] got 0.8665861235761132 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:18<00:00,  9.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 0, 2] got 0.8653779772178115 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:16<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 11, 0, 3] got 0.8636520538488092 on validation.\n",
      "VAL INGREDIENTS [4, 6, 10, 1, 11, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy souping accuracy: 0.8669313082499137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_val_df = pd.DataFrame(val_results)\n",
    "\n",
    "val_copy = results_val_df.copy()\n",
    "sorted_val = val_copy.sort_values(by= 'Val Accuracy',ascending=False)\n",
    "sorted_val.to_csv(os.path.join(test_save_path, \"VAL_RESULTS.csv\"), index=False)\n",
    "\n",
    "print(f\"Best model Val Accuracy: {sorted_val.iloc[0]['Val Accuracy']}\")\n",
    "print(f\"Second best model Val Accuracy: {sorted_val.iloc[1]['Val Accuracy']}\")\n",
    "print(f\"Worst model Val Accuracy: {sorted_val.iloc[-1]['Val Accuracy']}\")\n",
    "\n",
    "#UNIFORM\n",
    "print(\"Uniform souping ...\")\n",
    "alphal = [1 / len(state_dicts) for i in range(len(state_dicts))]\n",
    "model = get_model(MODEL, PRETRAINED, num_classes, FREEZE)\n",
    "uniform_model = souping(model, state_dicts, alphal)\n",
    "uniform_model.to(DEVICE)\n",
    "\n",
    "uniform_test_loss, uniform_test_acc  = val_step(uniform_model, test_loader, loss, DEVICE)\n",
    "print(f\"Uniform souping accuracy: {uniform_test_acc}\")\n",
    "\n",
    "#greedy\n",
    "\n",
    "print(\"Greedy souping ...\")\n",
    "model = get_model(MODEL, PRETRAINED, num_classes, FREEZE)\n",
    "\n",
    "val_res = list(results_val_df['Val Accuracy'])\n",
    "greedy_model, best_ingredients = greedy_souping_2(state_dicts, val_res, test_loader, loss, DEVICE, num_classes)\n",
    "greedy_model.to(DEVICE)\n",
    "print('VAL INGREDIENTS',best_ingredients)\n",
    "greedy_test_loss, greedy_test_acc = val_step(greedy_model, test_loader, loss, DEVICE)\n",
    "\n",
    "print(f\"Greedy souping accuracy: {greedy_test_acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model Val Accuracy: 0.8626164998274076\n",
      "Second best model Val Accuracy: 0.8603727994477045\n",
      "Worst model Val Accuracy: 0.8117017604418364\n",
      "Uniform souping ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform souping accuracy: 0.8629616845012081\n",
      "Greedy souping ...\n",
      "[4, 6, 0, 5, 10, 11, 9, 8, 7, 1, 2, 3]\n",
      "currentttttttt bestttttttt 0.8626164998274076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:17<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6] got 0.8631342768381084 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 0] got 0.8627890921643079 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:15<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 5] got 0.8627890921643079 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:19<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10] got 0.8643424231964101 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:17<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 11] got 0.8634794615119089 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:18<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 9] got 0.8638246461857093 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:15<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 8] got 0.8639972385226096 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 7] got 0.8633068691750087 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:19<00:00,  9.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1] got 0.8658957542285123 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 2] got 0.8629616845012081 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:17<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 10, 1, 3] got 0.8626164998274076 on validation.\n",
      "VAL INGREDIENTS [4, 6, 10, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:21<00:00,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy souping accuracy: 0.8658957542285123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_val_df = pd.DataFrame(val_results)\n",
    "\n",
    "val_copy = results_val_df.copy()\n",
    "sorted_val = val_copy.sort_values(by= 'Val Accuracy',ascending=False)\n",
    "sorted_val.to_csv(os.path.join(test_save_path, \"VAL_RESULTS.csv\"), index=False)\n",
    "\n",
    "print(f\"Best model Val Accuracy: {sorted_val.iloc[0]['Val Accuracy']}\")\n",
    "print(f\"Second best model Val Accuracy: {sorted_val.iloc[1]['Val Accuracy']}\")\n",
    "print(f\"Worst model Val Accuracy: {sorted_val.iloc[-1]['Val Accuracy']}\")\n",
    "\n",
    "#UNIFORM\n",
    "print(\"Uniform souping ...\")\n",
    "alphal = [1 / len(state_dicts) for i in range(len(state_dicts))]\n",
    "model = get_model(MODEL, PRETRAINED, num_classes, FREEZE)\n",
    "uniform_model = souping(model, state_dicts, alphal)\n",
    "uniform_model.to(DEVICE)\n",
    "\n",
    "uniform_test_loss, uniform_test_acc  = val_step(uniform_model, test_loader, loss, DEVICE)\n",
    "print(f\"Uniform souping accuracy: {uniform_test_acc}\")\n",
    "\n",
    "#greedy\n",
    "\n",
    "print(\"Greedy souping ...\")\n",
    "model = get_model(MODEL, PRETRAINED, num_classes, FREEZE)\n",
    "\n",
    "val_res = list(results_val_df['Val Accuracy'])\n",
    "greedy_model, best_ingredients = greedy_souping(state_dicts, val_res, test_loader, loss, DEVICE, num_classes)\n",
    "greedy_model.to(DEVICE)\n",
    "print('VAL INGREDIENTS',best_ingredients)\n",
    "greedy_test_loss, greedy_test_acc = val_step(greedy_model, test_loader, loss, DEVICE)\n",
    "\n",
    "print(f\"Greedy souping accuracy: {greedy_test_acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model Val Accuracy: 0.8626164998274076\n",
      "Second best model Val Accuracy: 0.8603727994477045\n",
      "Worst model Val Accuracy: 0.8117017604418364\n",
      "Uniform souping ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:18<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform souping accuracy: 0.8629616845012081\n",
      "Greedy souping ...\n",
      "[4, 6, 0, 5, 10, 11, 9, 8, 7, 1, 2, 3]\n",
      "currentttttttt bestttttttt 0.8626164998274076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 5, 10, 11, 9, 8, 7, 1, 2, 3] got 0.8631342768381084 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:17<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [4, 6, 5, 11, 9, 8, 7, 1, 2, 3] got 0.8634794615119089 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:21<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 5, 11, 9, 8, 7, 1, 2, 3] got 0.8639972385226096 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:19<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 11, 9, 8, 7, 1, 2, 3] got 0.8638246461857093 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 5, 11, 8, 7, 1, 2, 3] got 0.8641698308595098 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:18<00:00,  9.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 11, 8, 7, 1, 2, 3] got 0.8624439074905074 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:24<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 5, 11, 8, 7, 1, 2] got 0.8622713151536072 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:19<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 5, 11, 8, 7, 1, 3] got 0.8634794615119089 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:20<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 5, 11, 8, 1, 2, 3] got 0.8627890921643079 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:17<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [5, 11, 8, 7, 1, 2, 3] got 0.8622713151536072 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:18<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 5, 11, 7, 1, 2, 3] got 0.8634794615119089 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:16<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 5, 8, 7, 1, 2, 3] got 0.8631342768381084 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:18<00:00,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 5, 11, 8, 7, 2, 3] got 0.8624439074905074 on validation.\n",
      "VAL INGREDIENTS [6, 5, 11, 8, 7, 1, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:18<00:00, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy souping accuracy: 0.8641698308595098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_val_df = pd.DataFrame(val_results)\n",
    "\n",
    "val_copy = results_val_df.copy()\n",
    "sorted_val = val_copy.sort_values(by= 'Val Accuracy',ascending=False)\n",
    "sorted_val.to_csv(os.path.join(test_save_path, \"VAL_RESULTS.csv\"), index=False)\n",
    "\n",
    "print(f\"Best model Val Accuracy: {sorted_val.iloc[0]['Val Accuracy']}\")\n",
    "print(f\"Second best model Val Accuracy: {sorted_val.iloc[1]['Val Accuracy']}\")\n",
    "print(f\"Worst model Val Accuracy: {sorted_val.iloc[-1]['Val Accuracy']}\")\n",
    "\n",
    "#UNIFORM\n",
    "# print(\"Uniform souping ...\")\n",
    "# alphal = [1 / len(state_dicts) for i in range(len(state_dicts))]\n",
    "# model = get_model(MODEL, PRETRAINED, num_classes, FREEZE)\n",
    "# uniform_model = souping(model, state_dicts, alphal)\n",
    "# uniform_model.to(DEVICE)\n",
    "\n",
    "# uniform_test_loss, uniform_test_acc  = val_step(uniform_model, test_loader, loss, DEVICE)\n",
    "# print(f\"Uniform souping accuracy: {uniform_test_acc}\")\n",
    "\n",
    "#greedy\n",
    "\n",
    "print(\"Greedy souping ...\")\n",
    "model = get_model(MODEL, PRETRAINED, num_classes, FREEZE)\n",
    "\n",
    "val_res = list(results_val_df['Val Accuracy'])\n",
    "greedy_model, best_ingredients = prune_souping_random(state_dicts, val_res, test_loader, loss, DEVICE, num_classes)\n",
    "greedy_model.to(DEVICE)\n",
    "print('VAL INGREDIENTS',best_ingredients)\n",
    "greedy_test_loss, greedy_test_acc = val_step(greedy_model, test_loader, loss, DEVICE)\n",
    "\n",
    "print(f\"Greedy souping accuracy: {greedy_test_acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model Val Accuracy: 0.8626164998274076\n",
      "Second best model Val Accuracy: 0.8603727994477045\n",
      "Worst model Val Accuracy: 0.8117017604418364\n",
      "Uniform souping ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:19<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform souping accuracy: 0.8629616845012081\n",
      "Greedy souping ...\n",
      "[4, 6, 0, 5, 10, 11, 9, 8, 7, 1, 2, 3]\n",
      "currentttttttt bestttttttt 0.8626164998274076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:19<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 0, 5, 10, 11, 9, 8, 7, 1, 2, 3] got 0.8627890921643079 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:17<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 5, 10, 11, 9, 8, 7, 1, 2, 3] got 0.8633068691750087 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:21<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 10, 11, 9, 8, 7, 1, 2, 3] got 0.8641698308595098 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:18<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 11, 9, 8, 7, 1, 2, 3] got 0.8638246461857093 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 182/182 [00:19<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models [6, 10, 9, 8, 7, 1, 2, 3] got 0.8639972385226096 on validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|#####9    | 109/182 [00:09<00:05, 13.32it/s]"
     ]
    }
   ],
   "source": [
    "results_val_df = pd.DataFrame(val_results)\n",
    "\n",
    "val_copy = results_val_df.copy()\n",
    "sorted_val = val_copy.sort_values(by= 'Val Accuracy',ascending=False)\n",
    "sorted_val.to_csv(os.path.join(test_save_path, \"VAL_RESULTS.csv\"), index=False)\n",
    "\n",
    "print(f\"Best model Val Accuracy: {sorted_val.iloc[0]['Val Accuracy']}\")\n",
    "print(f\"Second best model Val Accuracy: {sorted_val.iloc[1]['Val Accuracy']}\")\n",
    "print(f\"Worst model Val Accuracy: {sorted_val.iloc[-1]['Val Accuracy']}\")\n",
    "\n",
    "#UNIFORM\n",
    "# print(\"Uniform souping ...\")\n",
    "# alphal = [1 / len(state_dicts) for i in range(len(state_dicts))]\n",
    "# model = get_model(MODEL, PRETRAINED, num_classes, FREEZE)\n",
    "# uniform_model = souping(model, state_dicts, alphal)\n",
    "# uniform_model.to(DEVICE)\n",
    "\n",
    "# uniform_test_loss, uniform_test_acc  = val_step(uniform_model, test_loader, loss, DEVICE)\n",
    "# print(f\"Uniform souping accuracy: {uniform_test_acc}\")\n",
    "\n",
    "#greedy\n",
    "\n",
    "print(\"Greedy souping ...\")\n",
    "model = get_model(MODEL, PRETRAINED, num_classes, FREEZE)\n",
    "\n",
    "val_res = list(results_val_df['Val Accuracy'])\n",
    "greedy_model, best_ingredients = prune_souping_sorted(state_dicts, val_res, test_loader, loss, DEVICE, num_classes)\n",
    "greedy_model.to(DEVICE)\n",
    "print('VAL INGREDIENTS',best_ingredients)\n",
    "greedy_test_loss, greedy_test_acc = val_step(greedy_model, test_loader, loss, DEVICE)\n",
    "\n",
    "print(f\"Greedy souping accuracy: {greedy_test_acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #saving results in table\n",
    "# print(\"Creating table ...\")\n",
    "# table = pd.DataFrame(columns=['Model Name', 'Test Accuracy', 'Test F1', 'Test Recall', 'Test Kappa','Test AUC','Augmentation', 'Learning Rate', 'SEED'])\n",
    "\n",
    "# #get best, second best and worst model from sorted_test and add them to the table\n",
    "# best_model = sorted_test.iloc[0]\n",
    "# second_best_model = sorted_test.iloc[1]\n",
    "# worst_model = sorted_test.iloc[-1]\n",
    "\n",
    "# #rename model name in best, second best and worst model\n",
    "# best_model['Model Name'] = f\"Best 1: {best_model['Model Name']}\"\n",
    "# second_best_model['Model Name'] = f\"Best 2: {second_best_model['Model Name']}\"\n",
    "# worst_model['Model Name'] = f\"Worst: {worst_model['Model Name']}\"\n",
    "\n",
    "# table.loc[0] = best_model\n",
    "# table.loc[1] = second_best_model\n",
    "# table.loc[2] = worst_model\n",
    "\n",
    "# #add uniform and greedy to the table\n",
    "# table.loc[3] = {'Model Name': 'Uniform',\n",
    "#                                     'Test Accuracy': uniform_test_acc,\n",
    "#                                     }\n",
    "\n",
    "# table.loc[4] = {'Model Name': 'Greedy',\n",
    "#                                     'Test Accuracy': greedy_test_acc,\n",
    "#                                     }\n",
    "\n",
    "\n",
    "\n",
    "# #save the table to csv without index\n",
    "# table.to_csv(os.path.join(test_save_path, \"ALL.csv\"), index=False)\n",
    "# print(table.to_markdown())\n",
    "# print(\"Table saved to ALL.csv\")\n",
    "\n",
    "\n",
    "# lr_state_dicts = state_dicts.copy()\n",
    "# val_results_copy = results_val_df.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for j in range(3,8):\n",
    "#     print(f\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>LR{j}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "#     indexes = []\n",
    "#     for i in val_results_copy.iterrows():\n",
    "#         if f\"-0{j}\" in i[1]['Learning Rate']:\n",
    "#             indexes.append(i[0])\n",
    "    \n",
    "#     #remove from val_results_copy all the rows with indexes and reset the index\n",
    "#     val_results_copy = val_results_copy.drop(indexes).reset_index(drop=True)\n",
    "#     test_results_copy = test_results_copy.drop(indexes).reset_index(drop=True)\n",
    "\n",
    "#     sorted_val = val_results_copy.sort_values(by= val_sort_by,ascending=False)\n",
    "#     sorted_test = test_results_copy.sort_values(by= test_sort_by,ascending=False)\n",
    "\n",
    "#     sorted_val.to_csv(os.path.join(test_save_path, f\"VAL_RESULTS_LR<-0{j}.csv\"), index=False)\n",
    "#     sorted_test.to_csv(os.path.join(test_save_path, f\"TEST_RESULTS_LR<-0{j}.csv\"), index=False)\n",
    "\n",
    "#     #remove from lr_state_dicts all the state_dicts with indexes\n",
    "#     lr_state_dicts = [i for j, i in enumerate(lr_state_dicts) if j not in indexes]\n",
    "\n",
    "#     #if state_dict is empty break\n",
    "#     if len(lr_state_dicts) == 0:\n",
    "#         print(\"No more models to analyze!\")\n",
    "#         break\n",
    "\n",
    "#     print(f\"Models with Learning rate -0{j} removed ...\")\n",
    "\n",
    "#     print(f\"Best model {val_sort_by}: {sorted_val.iloc[0][val_sort_by]}\")\n",
    "#     print(f\"Second best model {val_sort_by}: {sorted_val.iloc[1][val_sort_by]}\")\n",
    "#     print(f\"Worst model {val_sort_by}: {sorted_val.iloc[-1][val_sort_by]}\")\n",
    "#     #UNIFORM\n",
    "#     print(\"Unifrom souping ...\")\n",
    "#     alphal = [1 / len(lr_state_dicts) for i in range(len(lr_state_dicts))]\n",
    "#     model = get_model(model_config[\"MODEL\"], num_classes=NUM_CLASSES)\n",
    "#     uniform_model = souping(model, lr_state_dicts, alphal)\n",
    "#     uniform_model.to(DEVICE)\n",
    "\n",
    "#     uniform_test_loss, uniform_test_acc, uniform_test_f1, uniform_test_recall, uniform_test_kappa, uniform_test_auc = val_step(uniform_model, test_loader, train_loader, loss, DEVICE, CLASSIFICATION)\n",
    "\n",
    "#     #greedy\n",
    "#     print(\"Greedy souping ...\")\n",
    "#     model = get_model(model_config[\"MODEL\"], num_classes=NUM_CLASSES)\n",
    "\n",
    "#     val_metric = list(val_results_copy[val_sort_by])\n",
    "#     greedy_model, best_ingredients = greedy_souping(lr_state_dicts, val_metric, model_config[\"MODEL\"], NUM_CLASSES, val_loader, train_loader, loss, DEVICE, CLASSIFICATION, val_sort_by)\n",
    "#     greedy_model.to(DEVICE)\n",
    "#     print(best_ingredients)\n",
    "#     greedy_test_loss, greedy_test_acc, greedy_test_f1, greedy_test_recall, greedy_test_kappa, greedy_test_auc = val_step(greedy_model, test_loader, train_loader, loss, DEVICE, CLASSIFICATION)\n",
    "\n",
    "#     test_metric = list(results_test_df[test_sort_by])\n",
    "#     greedy_model_test, best_ingredients_test = greedy_souping(state_dicts, test_metric, model_config[\"MODEL\"], NUM_CLASSES, test_loader, train_loader, loss, DEVICE, CLASSIFICATION, test_sort_by)\n",
    "#     print(best_ingredients_test)\n",
    "#     greedy_model_test.to(DEVICE)\n",
    "#     greedy_test_loss_test, greedy_test_acc_test, greedy_test_f1_test, greedy_test_recall_test, greedy_test_kappa_test, greedy_test_auc_test = val_step(greedy_model_test, test_loader, train_loader, loss, DEVICE, CLASSIFICATION)\n",
    "\n",
    "\n",
    "\n",
    "#     #saving results in table\n",
    "#     print(\"Creating table ...\")\n",
    "#     table = pd.DataFrame(columns=['Model Name', 'Test Accuracy', 'Test F1', 'Test Recall','Test kAPPA','Test AUC', 'Augmentation', 'Learning Rate', 'SEED'])\n",
    "\n",
    "#     #get best, second best and worst model from sorted_test and add them to the table\n",
    "#     best_model = sorted_test.iloc[0]\n",
    "#     second_best_model = sorted_test.iloc[1]\n",
    "#     worst_model = sorted_test.iloc[-1]\n",
    "\n",
    "#     #rename model name in best, second best and worst model\n",
    "#     best_model['Model Name'] = f\"Best 1: {best_model['Model Name']}\"\n",
    "#     second_best_model['Model Name'] = f\"Best 2: {second_best_model['Model Name']}\"\n",
    "#     worst_model['Model Name'] = f\"Worst: {worst_model['Model Name']}\"\n",
    "\n",
    "#     table.loc[0] = best_model\n",
    "#     table.loc[1] = second_best_model\n",
    "#     table.loc[2] = worst_model\n",
    "\n",
    "#     #add uniform and greedy to the table\n",
    "#     table.loc[3] = {'Model Name': 'Uniform',\n",
    "#                                         'Test Accuracy': uniform_test_acc,\n",
    "#                                         'Test F1': uniform_test_f1,\n",
    "#                                         'Test Recall': uniform_test_recall,\n",
    "#                                         'Test Kappa': uniform_test_kappa,\n",
    "#                                         'Test AUC': uniform_test_auc,\n",
    "#                                         'Augmentation': 'None',\n",
    "#                                         'Learning Rate': 'None',\n",
    "#                                         'SEED': 'None'}\n",
    "\n",
    "#     table.loc[4] = {'Model Name': 'Greedy',\n",
    "#                                         'Test Accuracy': greedy_test_acc,\n",
    "#                                         'Test F1': greedy_test_f1,\n",
    "#                                         'Test Recall': greedy_test_recall,\n",
    "#                                         'Test Kappa': greedy_test_kappa,\n",
    "#                                         'Test AUC': greedy_test_auc,\n",
    "#                                         'Augmentation': 'None',\n",
    "#                                         'Learning Rate': 'None',\n",
    "#                                         'SEED': 'None'}\n",
    "\n",
    "#     #save the table to csv without index\n",
    "#     table.to_csv(os.path.join(test_save_path, f\"LR<-0{j}.csv\"), index=False)\n",
    "#     print(table.to_markdown())\n",
    "#     print(f\"Table saved to LR<-0{j}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV701_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
